{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChromaDB を使った RAG のデモ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI API Key とLLM、埋め込みモデルの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "# 環境変数 OPENAI_API_KEY に OpenAI API Key を設定（.env ファイルの OPENAI_API_KEY からロード）\n",
    "_ = load_dotenv(find_dotenv())\n",
    "embedding_model = \"text-embedding-3-large\" # 埋め込みモデル\n",
    "model = \"gpt-4o\" # LLM\n",
    "temperature = 0 # LLMの生成のランダムさ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLMと埋め込みモデルの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# LLMの準備\n",
    "llm = ChatOpenAI(\n",
    "    model=model, # モデル\n",
    "    temperature=temperature, # ランダムさ\n",
    ")\n",
    "\n",
    "# 埋め込みモデルの準備\n",
    "embeddings = OpenAIEmbeddings(model=embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検索対象の ChromaDB コレクション名の設定\n",
    "コレクションとは、ChromaDB におけるベクトルデータの保存単位で、RDB のテーブルのようなもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection_name = \"mycollection_100\" # 検索対象のChromadb コレクション名（チャンクサイズ100文字で事前に作成済み）\n",
    "collection_name = \"mycollection_200\" # 検索対象のChromadb コレクション名（チャンクサイズ200文字で事前に作成済み）\n",
    "#collection_name = \"mycollection_500\" # 検索対象のChromadb コレクション名（チャンクサイズ500文字で事前に作成済み）\n",
    "#collection_name = \"mycollection_1000\" # 検索対象のChromadb コレクション名（チャンクサイズ1000文字で事前に作成済み）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VectorStoreの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# LangChain の Chromadb VectorStore のインスタンスを作成\n",
    "vector_store = Chroma(\n",
    "    client=chromadb.PersistentClient(path=\"./chroma_db\"),\n",
    "    collection_name=collection_name,\n",
    "    embedding_function=embeddings,\n",
    "    collection_metadata={\"hnsw:space\": \"ip\"} \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieverの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 4}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplateの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"あなたの仕事は、human の question に答えることです。以下の手順で回答してください。前置きや思考経過は出力しないでください。context の中の source のファイル名には、page_content の主題が含まれています。最初に、 context に書かれている情報だけを使用して、question の質問に答えることができるかどうか判断してください、判断結果は出力しません。次に、context にある情報だけで回答が可能と判断した場合は、context に書かれている情報だけを使用して、question の質問に答えてください。context にある情報だけでは回答できないと判断した場合は、情報がないので回答できないと答えてください。\\n\\ncontext: {context}\"),\n",
    "        (\"human\", \"question: {input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGチェーンの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"input\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | (lambda x: print(f\"\\n=== Generated Prompt ===\\n{x}\\n========================\\n\\n\") or x)  # プロンプトを表示\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 質問の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query=\"ハグリッドがホグワーツへの入学案内書を持ってきたのはいつですか？それはどのような日でしたか？\"\n",
    "#query=\"アメリカの初代大統領は誰ですか？\"\n",
    "query=\"時空管理局のアースラの艦長は誰ですか？\"\n",
    "#query=\"フェイトが留学生として通った小学校は？\"\n",
    "#query=\"ユーノ・スクライアは、普段どのような動物の姿で過ごしていますか？\"\n",
    "#query=\"聖王のゆりかごとは何ですか、どのくらいの大きさですか？\"\n",
    "#query=\"スターライトブレイカーは誰のどのような魔法ですか？\"\n",
    "#query=\"高町なのはが小学生のときに通っていた学校は？\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAGの実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generated Prompt ===\n",
      "messages=[SystemMessage(content=\"あなたの仕事は、human の question に答えることです。以下の手順で回答してください。前置きや思考経過は出力しないでください。context の中の source のファイル名には、page_content の主題が含まれています。最初に、 context に書かれている情報だけを使用して、question の質問に答えることができるかどうか判断してください、判断結果は出力しません。次に、context にある情報だけで回答が可能と判断した場合は、context に書かれている情報だけを使用して、question の質問に答えてください。context にある情報だけでは回答できないと判断した場合は、情報がないので回答できないと答えてください。\\n\\ncontext: [Document(metadata={'source': 'data\\\\\\\\Wikipedia-魔法科高校の劣等生.pdf'}, page_content='剛健でありながらスマートな雰囲気を⾝に纏う40歳前後の男性でリーナより2つ歳下の娘を持つ。スターズの中でも有数の常識⼈。2097年6⽉18⽇の早朝に、スターズ第⼗⼀隊のシャウラ少尉からの報告を受けてアルゴル少尉やミルファク少尉を含めた四⼈でリーナの救出に向かい、リーナを基地から脱出させることに成功するが、アルゴル少尉やシャウラ少尉と共に捕らえられる。'), Document(metadata={'source': 'data\\\\\\\\Wikipedia-八神はやて.pdf'}, page_content='⼀⽅フェイトを驚かせる⼀⾯もあった。『StrikerS』におけるはやて空港⽕災の後、管理局の対応の遅さを嘆き、周りの協⼒を得て本局遺失物管理部「機動六課」を4年がかりで設⽴[15]。機動六課の課⻑、機動六課本部隊舎の総部隊⻑、後⽅⽀援部隊「ロングアーチ」の指揮官を務める。'), Document(metadata={'source': 'data\\\\\\\\Wikipedia-魔法科高校の劣等生.pdf'}, page_content='⼆⼈はこれを受け⼊れる。そして⼆⼈を乗せた⾼千穂は深雪とリーナによる疑似瞬間移動によって宇宙に打ち上げられた。またレイモンドは達也からの通告を受け、USNA政府に⾝柄を移されることとなり、⽕星探査船に乗せられる形で宇宙へ放逐されることとなったが、本⼈は魔法による宇宙開発を望んでいたこともあって、むしろ喜んで旅⽴っていった。'), Document(metadata={'source': 'data\\\\\\\\Wikipedia-魔法科高校の劣等生.pdf'}, page_content='フォーマルハウト中尉の上官であった。達也が『魔法恒星炉エネルギープラント計画』を発表した後、リーナとカノープス少佐がウォーカー⼤佐から告げられた、達也のエネルギープラント計画に対する破壊⼯作とそれに伴う達也の暗殺に反対意⾒を具申して退出した後、ベガ⼤尉と共にウォーカー⼤佐に呼び出されて出頭し、先述の破壊⼯作と暗殺の任務を命じられて、気が進まないながらも了承する。')]\", additional_kwargs={}, response_metadata={}), HumanMessage(content='question: 時空管理局のアースラの艦長は誰ですか？', additional_kwargs={}, response_metadata={})]\n",
      "========================\n",
      "\n",
      "\n",
      "=== LLM response ======\n",
      "content='情報がないので回答できません。' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 933, 'total_tokens': 941, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_a79d8dac1f', 'finish_reason': 'stop', 'logprobs': None} id='run-d5e8af62-4fa0-4a0d-b47b-8802e629652a-0' usage_metadata={'input_tokens': 933, 'output_tokens': 8, 'total_tokens': 941, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "========================\n",
      "\n",
      "=== 回答 ===============\n",
      "情報がないので回答できません。\n",
      "========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke(query)\n",
    "print(f\"=== LLM response ======\\n{response}\\n========================\\n\")\n",
    "print(f\"=== 回答 ===============\\n{response.content}\\n========================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
